# SPDX-FileCopyrightText: : 2025 The PyPSA-China Authors
# SPDX-License-Identifier: MIT

import yaml
import shutil
from pathlib import Path
from snakemake.utils import min_version
import logging
import os.path
import logging

from scripts._helpers import PathManager, get_cutout_params, ConfigManager

# NB: duplicated parameters will be overwritten by the last read cfg

configfile: "config/default_config.yaml"
configfile: "config/technology_config.yaml"
configfile: "config/plot_config.yaml"
configfile: "config/global_energy_monitor.yaml"

configfile: "config/config.yaml"

# for dev of remind with mocksnakemake, can activate this
# configfile: "resources/tmp/remind_coupled_cg.yaml"


# ====== make paths =======
config_manager = ConfigManager(config)
config = config_manager.handle_scenarios()

# ====== set global parameters =======
ATLITE_NPROCESSES = config['atlite'].get('nprocesses', 4)
CUTOUT_NAME= config["atlite"]["cutout_name"]
# for pathways, first point should be near-fixed by existing capacities and is baseyear
# for overnight it refers to existing infrastructure
BASEYEAR = min([int(y) for y in config["scenario"]["planning_horizons"]])

# ====== make paths =======
path_manager = PathManager(config)
RESULTS_DIR = path_manager.results_dir()
DERIVED_DATA = path_manager.derived_data_dir(shared=False)
DERIVED_COMMON = path_manager.derived_data_dir(shared=True)
DERIVED_CUTOUT = DERIVED_COMMON + f"/cutout_{CUTOUT_NAME}"
COSTS_DATA = path_manager.costs_dir()
LOG_DIR = path_manager.logs_dir()
LOGS_COMMON = "logs"
LU_RASTER = path_manager.landuse_raster_data()
CUTOUT_PATH = os.path.join(path_manager.cutouts_dir(),CUTOUT_NAME + ".nc")

# ====== include rules ======= (after paths are set!)
include: "rules/prepare_remind_coupled.smk"
include: "rules/postprocess.smk"
include: "rules/fetch_data.smk"
include: "rules/visualize_inputs.smk"


if config["run"].get("is_test", False):
    localrules: plot_all, plot_summary, plot_snapshots, build_population, dag, fetch_region_shapes, plot_input_costs

# ====== set up snakemake providers =======
storage:
    provider="http",

# ======= PSEUDO RULES TO EXECUTE WORKFLOW =========
if config["run"].get("is_test", False):
    rule test_workflow:
        input:
            expand(RESULTS_DIR+ '/postnetworks/ntwk_{planning_horizons}.nc',   
            **{k: v for k, v in config["scenario"].items() if k != "planing_horizons"},
            ),

elif config["foresight"] in ["overnight", "myopic"]:
    rule plot_all:
        input:
            expand(
                RESULTS_DIR+ '/plots/_summary/pathway_costs.png',
                **{k: v for k, v in config["scenario"].items() if k != "planning_horizons"},
            ),
            # network plot
            expand(
                RESULTS_DIR+"/plots/networks/ntwk_{planning_horizons}-cost.png",      
                **config["scenario"]
            ),
            expand(RESULTS_DIR+"/plots/statistics_{planning_horizons}/", **config["scenario"]),
            expand(RESULTS_DIR + "/plots/snapshots_{planning_horizons}/", **config["scenario"]),
else:
    raise ValueError("Invalid scenario config: {}".format(config["foresight"]))


#    ======== Workflow ===========
# TODO regions
if config['enable'].get('build_cutout', False):
    rule build_cutout:
        params:
            config=config
        # TODO fix paths?
        input:
            regions_onshore="regions_onshore/dataregions/regions_onshore.geojson",
            regions_offshore="regions_offshore/dataregions/regions_offshore.geojson",
        output: CUTOUT_PATH,
        log: LOGS_COMMON + f"/build_cutout/{CUTOUT_NAME}.log"
        benchmark: f"benchmarks/build_cutout_{CUTOUT_NAME}"
        threads: ATLITE_NPROCESSES
        resources: mem_mb=ATLITE_NPROCESSES * 1000
        script: "scripts/build_cutout.py"


pop_raster = name = "-".join([str(v) for v in config["world_population_raster"].values()])
rule build_population_layouts:
    params:
        pop_year = 2018, # for urban and province, for gridded see fetch
        pop_conversion = 1e4, # conversion for province_populations
        coarsen_pop_by = 3, # save space and memory
    input:
        province_populations="resources/data/population/population_from_national_data.csv",
        population_gridded=f"resources/data/population/china_world_pop_{name}.tif",
        province_shape="resources/data/regions/provinces_onshore.geojson",
        admin_l2_shape = "resources/data/regions/admin2_shapes.geojson",
        urban_percent="resources/data/population/china_urban_population_proportion_2013_2022.csv",
    output:
        pop_layouts=DERIVED_COMMON + "/population/pop_layout.nc",
        admin2_population=DERIVED_COMMON + "/population/pop_distributions.csv",
    # log:
    #     LOGS_COMMON + "/build_population_layouts.log",
    script:
        "scripts/build_population_layouts.py"


rule build_shapes:
    params:
        simplify_tol = config["fetch_regions"]["simplify_tol"],
        node_config = config["nodes"],
        # TODO use , move to settings
        offshore_provinces = [ "Fujian", "Guangdong", "Guangxi", "Hainan", "Hebei", "Jiangsu", "Liaoning", "Shandong", "Shanghai", "Tianjin", "Zhejiang",]
    input:
        province_shapes="resources/data/regions/provinces_onshore.geojson",
        admin_l2_shapes="resources/data/regions/admin2_shapes.geojson",
        offshore_shapes="resources/data/regions/country_offshore.geojson",
        gdp = "resources/data/population/admin_l2_yang_et_al_corrected_gdp_2018.csv",
    output:
        offshore_shapes=DERIVED_COMMON + "/regions/regions_offshore.geojson",
        regions_w_gdp=DERIVED_COMMON + "/regions/regions_w_gdp.geojson",
    log:
        LOGS_COMMON + "/build_shapes.log",
    script:
        "scripts/build_shapes.py"


rule base_network:
    """Base Network with buses & edges.
    This is at Admin l2 resolution and not at substation resolution, the assumption
    is that each admin l2 population center has a substation
    FOR NOW take the admin2 centroid as bus location -> could switch to highest density point"""
    params:
        refyear=2018, # temp for snapshots
        snapshots=config["snapshots"],
        drop_leap_day=True, # False will raise NotImplemented error
        lines_path="resources/data/grids/gem_uhv_with_admin2.csv",
        node_config = config["nodes"],
        line_margin = config["security"].get("line_security_margin", 70) / 100,
    input:
        province_shapes="resources/data/regions/provinces_onshore.geojson",
        admin_l2_shapes ="resources/data/regions/admin2_shapes.geojson",
        offshore_shapes=DERIVED_COMMON + "/regions/regions_offshore.geojson",
    output:
        base_network=DERIVED_COMMON + "/networks/base_l2.nc",
    script:
        "scripts/base_network_l2.py"

# rule build_clustered_population_layouts:
#     input:
#         pop_layout_total=resources("pop_layout_total.nc"),
#         pop_layout_urban=resources("pop_layout_urban.nc"),
#         pop_layout_rural=resources("pop_layout_rural.nc"),
#         regions(data"regions_onshore_base_s_{clusters}.geojson"),
#         cutout=lambda w: input_cutout(w),
#     output:
#         clustered_pop_layout=resources("pop_layout_base_s_{clusters}.csv"),
#     log:
#         logs("build_clustered_population_layouts_s_{clusters}.log"),
#     resources:
#         mem_mb=10000,
#     benchmark:
#         benchmarks("build_clustered_population_layouts/s_{clusters}")
#     conda:
#         "../envs/environment.yaml"
#     script:
#         "../scripts/build_clustered_population_layouts.py"

rule build_electricity_demand:
    """build the electricity demand at provincial and base network level"""
    params:
        # data_year=2018,
        distribution_key = {"gdp":0.6, "pop":0.4},
        config = config,
        elec_load_conversion = config["paths"]["yearly_regional_load"]["ac_to_mwh"]
    input:
        gdp = DERIVED_COMMON + "/regions/regions_w_gdp.geojson",
        population = DERIVED_COMMON + "/population/pop_distributions.csv",
        province_codes = "resources/data/regions/province_codes.csv",
        hrly_regional_elec_load = "resources/data/load/Hourly_demand_of_31_province_China_modified_V2.1.csv",
    output:
        # provincial_load = DERIVED_DATA + "/load/provincial_hrly_elec_load.h5",
        base_network_load = DERIVED_DATA + "/load/base_network_hrly_elec_load.nc",
    log: LOG_DIR + "/build_elec_demand.log"
    script:
        "scripts/build_elec_demand.py"

# TODO add name database for custom clustering
cluster_id = config["nodes"].get("custom_name", "")
rule cluster_network:
    """A simplified clustering based on l2 shapes (341) -> n user clusters
    This will be replaced by PyPSA-EUR clustering when full osm network
    is checked and added"""
    params:
        node_config = config["nodes"],
        # line_margin = config["security"].get("line_security_margin", 70) / 100,
    input:
        admin_l2_shapes ="resources/data/regions/admin2_shapes.geojson",
        offshore_shapes=DERIVED_COMMON + "/regions/regions_offshore.geojson",
        base_network=DERIVED_COMMON + "/networks/base_l2.nc",
        #load=DERIVED_DATA + "/load/base_network_hrly_elec_load.nc",
    output:
        clustered_network=DERIVED_COMMON + f"/networks/base_clustered_s_{cluster_id}.nc",
        busmap = DERIVED_COMMON + f"/networks/busmap_clustered_s_{cluster_id}.csv",
        regions_offshore=DERIVED_COMMON + f"/regions/regions_offshore_s_{cluster_id}.geojson",
        regions_onshore=DERIVED_COMMON + f"/regions/regions_onshore_s_{cluster_id}.geojson",
    script:
        "scripts/cluster_network_l2.py"


rule build_powerplants:
    """ Groups power plants by node"""
    params:
        gem = config["global_energy_monitor_plants"],
        technologies = config["existing_capacities"]["techs"],
        grouped_years = config["existing_capacities"]["grouping_years"],
        config = config,
    input:
        GEM_plant_tracker="resources/data/existing_infrastructure/gem_data_raw/Global-integrated-Plant-Tracker-July-2025_china.xlsx",
        nodes=DERIVED_COMMON + f"/regions/regions_onshore_s_{cluster_id}.geojson",
        offshore_nodes=DERIVED_COMMON + f"/regions/regions_offshore_s_{cluster_id}.geojson",
        network=DERIVED_COMMON + f"/networks/base_clustered_s_{cluster_id}.nc",
    output:
        cleaned_ppls = DERIVED_COMMON + f"/existing_infrastructure/capacity_cleaned.csv",
    threads: 2 #TODO 1?
    script: "scripts/build_powerplants.py"


rule add_electricity:
    """ Add generators and links to clustered network"""
    params:
        config = config,
        snapshots=config["snapshots"],
        CHP_to_elec = not config.get("heat_coupling", False),
    input:
        costs=COSTS_DATA + "/costs_{planning_horizons}.csv",
        elec_projections=DERIVED_COMMON + "/load/electricity_projections_{planning_horizons}.csv",
        clustered_network=DERIVED_COMMON + f"/networks/base_clustered_s_{cluster_id}.nc",
        powerplants=DERIVED_COMMON + "/existing_infrastructure/capacity_cleaned.csv",
    output:
        elec_network=DERIVED_COMMON + "/networks/clustered_network_elec_{planning_horizons}.nc",

# TODO find a way to turn off if heat coupling is off 
rule build_solar_thermal_profiles:
    input:
        cutout=CUTOUT_PATH,
        # TODO change to new population
        population_map=DERIVED_COMMON+"/"+"population/population_gridcell_map.h5"
    output:
        profile_solar_thermal = DERIVED_CUTOUT+f"/heating/solar_thermal-{config['solar_thermal_angle']}.h5"
    log: LOGS_COMMON + "/build_solar_thermal_profiles.log"
    threads: 8
    resources: mem_mb=30000
    script: "scripts/build_solar_thermal_profiles.py"


rule build_temperature_profiles:
    params:
        nodes = config["nodes"],
    # TODO change to new population
    input:
        population_map=DERIVED_COMMON+"/"+"population/population_gridcell_map.h5",
        cutout=CUTOUT_PATH
    output:
        temp= DERIVED_CUTOUT + "/heating/temperature.h5"
    log: LOGS_COMMON + "/build_temperature_profiles.log"
    threads: 8
    resources: mem_mb=30000
    script: "scripts/build_temperature_profiles.py"

rule build_cop_profiles:
    params:
        nodes = config["nodes"],
    # TODO change to new population
    input:
        population_map=DERIVED_COMMON+"/"+"population/population_gridcell_map.h5",
        cutout=CUTOUT_PATH,
        temperature=DERIVED_CUTOUT + "/heating/temperature.h5",
    output:
        cop= DERIVED_CUTOUT + "/heating/hp_cop.h5",
    # threads: 8
    # resources: mem_mb=30000
    log: LOGS_COMMON + "/build_cop_profiles.log"
    script: "scripts/build_cop_profiles.py"


rasters = ["Build_up", "Grass", "Bare", "Shrubland"]
rule build_availability_matrix:
    params:
        nodes = config["nodes"],
    input:
        # GEBCO bathymetry (water depth)
        gebco=f"{LU_RASTER}/GEBCO_tiff/gebco_2024_CN.tif",
        cutout=CUTOUT_PATH,
        # TODO directly link to output of fetch region shapes
        # admin 1 level = first administrative level within country
        province_shape="resources/data/province_shapes/CHN_adm1.shp",
        offshore_province_shapes = "resources/data/regions/provinces_offshore.geojson",
        # natural reserves from WPGDA, available land
        **{
            f"natura{i+1}": "resources/data/landuse_availability/"
                        + f"WDPA_WDOECM_Oct2024_Public_CN_shp_{i}/"
                        + "WDPA_WDOECM_Oct2024_Public_CN_shp-polygons.shp"
            for i in range(3)
        },
        # available land:
        **{
            f"{raster}_raster": f"{LU_RASTER}/{raster}.tif"
            for raster in rasters
        },
    output:
        availability_matrix= DERIVED_CUTOUT + "/availability_matrix_{technology}.nc",
    log: LOGS_COMMON + "/build_availability_matrix_{technology}.log"
    script: "scripts/determine_availability_matrix.py"


rule build_renewable_profiles:
    params:
        config = config,
        resource_classes = lambda wildcards: config["renewable"][wildcards.technology]["resource_classes"]
    input:
        availability_matrix= DERIVED_CUTOUT + "/availability_matrix_{technology}.nc",
        province_shape="resources/data/province_shapes/CHN_adm1.shp",
        offshore_province_shapes="resources/data/regions/provinces_offshore.geojson",
        cutout=CUTOUT_PATH,
    output:
        profile=DERIVED_CUTOUT+"/"+"profile_{technology}-{rc_params}.nc",
        class_regions=DERIVED_CUTOUT+"/"+"{technology}_regions_by_class_{rc_params}.geojson",
        average_distance=DERIVED_CUTOUT+"/"+"average_distance_{technology}-{rc_params}.h5",
    log:
        LOGS_COMMON +f"/cutout_{CUTOUT_NAME}/" +"build_renewable_profile_{technology}-{rc_params}.log",
    threads: config["atlite"].get("nprocesses", 4)
    wildcard_constraints:
        technology="(?!hydro).*",  # Any technology other than hydro
    script:
        "scripts/build_renewable_profiles.py"


# # TODO check whether energy totals still needed
rule build_load_profiles:
    params:
        config = config,
        elec_load_conversion = config["paths"]["yearly_regional_load"]["ac_to_mwh"]
    input:
        population = DERIVED_COMMON + "/population/population.h5",
        population_map = DERIVED_COMMON + "/population/population_gridcell_map.h5",
        cutout = CUTOUT_PATH,
        intraday_profiles="resources/data/heating/heat_load_profile_DK_AdamJensen.csv",
        space_heat_demand="resources/data/heating/SPH_2020.csv",
        hot_water_demand="resources/data/heating/IEA_energysectorroadmaptocarbonneutralityinchina_fig325.csv",
        elec_load_projs = path_manager.elec_load(),
        province_codes = "resources/data/regions/province_codes.csv",
        hrly_regional_ac_load = "resources/data/load/Hourly_demand_of_31_province_China_modified_V2.1.csv",
    output:
        # TODO consider splitting into two rules so elect+hrly can be used DERIVED COMMON
        elec_load_hrly = DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
        heat_demand_profile = DERIVED_DATA + f"/heating-cutout_{CUTOUT_NAME}/"+"heat_demand_profile_{planning_horizons}.h5",
        energy_totals_name = DERIVED_DATA + "/" +f"energy_totals_{CUTOUT_NAME}_"+"{planning_horizons}.h5"
    log: LOG_DIR + "/build_load_profiles/build_{planning_horizons}"+f"_{CUTOUT_NAME}.log"
    threads: ATLITE_NPROCESSES
    resources: mem_mb = ATLITE_NPROCESSES * 5000
    script: "scripts/build_load_profiles.py"


rule build_biomass_potential:
    input:
        # from doi.org/10.1038/s41467-021-23282-x
        biomass_feedstocks = "resources/data/p_nom/41467_2021_23282_MOESM4_ESM.xlsx"
    log:
        LOGS_COMMON + "/build_biomass_potential.log"
    output:
        biomass_potential=DERIVED_COMMON+"/"+"p_nom/biomass_potential.h5"
    threads: ATLITE_NPROCESSES
    resources: mem_mb = ATLITE_NPROCESSES * 5000
    script: "scripts/build_biomass_potential.py"

# TODO move into add electricity
# NOTE: lifetimes are for the BASEYEAR and not brownfield construction year DateIn!
#       This could be changed if costs are merged into a single file
rule prepare_baseyear_capacities:
    """prepare inputs for add_existing_baseyear (optional in overnight mode)"""
    params:
        last_pypsa_cost_year = 2060,
        CHP_to_elec = not config.get("heat_coupling", False),
    input:
        # historical lifetimes from base year technoeconomic data
        tech_costs=path_manager.costs_dir() + f"/costs_{BASEYEAR}.csv",
        cleaned_ppls = DERIVED_COMMON + "/existing_infrastructure/capacity_cleaned.csv",
    output: 
        installed_capacities = DERIVED_DATA + '/existing_infrastructure/capacities_{planning_horizons}.csv',
    threads: 1
    resources: mem_mb=2000
    script: "scripts/prepare_existing_capacities.py"


# make sure the params will appear in the profile names
resource_class_cfg = {tech: config["renewable"][tech]["resource_classes"] for tech in config["renewable"]}
rsc_params = {key : "_".join([f"{k}{v}" for k, v in resource_class_cfg[key].items()]) for key in resource_class_cfg}
if config["foresight"] in ["overnight"]:
    add_brownfield = "-brownfield" if config["existing_capacities"].get("add", False) else ""

    rule prepare_networks:
        input:
            # TODO add a constant element for industry
            # TODO revisit central and decentral fractions
            # TODO revisit heating demand per provinces
            heat_demand_profile=DERIVED_DATA + f"/heating-cutout_{CUTOUT_NAME}/"+"heat_demand_profile_{planning_horizons}.h5",
            central_fraction="resources/data/heating/DH_city_town_2020.h5",
            solar_thermal_name=DERIVED_CUTOUT+f"/heating/solar_thermal-{config['solar_thermal_angle']}.h5",
            cop_name=DERIVED_CUTOUT+"/heating/hp_cop.h5",
            elec_load=DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
            intraday_profiles="resources/data/heating/heat_load_profile_DK_AdamJensen.csv",
            tech_costs = COSTS_DATA + "/costs_{planning_horizons}.csv",
            province_shape="resources/data/province_shapes/CHN_adm1.shp",
            biomass_potential=DERIVED_COMMON+f"{'/p_nom/biomass_potential.h5' if config["add_biomass"] else ''}",
            **{f"profile_{tech}": DERIVED_CUTOUT +f"/profile_{tech}-{rsc_params[tech]}.nc" for tech in config['renewable']},
        output:
            network_name=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
        threads: 1
        resources: mem_mb=10000
        script: "scripts/prepare_network.py"

    paidoff_caps = DERIVED_DATA + "/remind/harmonized_capacities/paid_off_capacities.csv"
    if not config["run"].get("is_remind_coupled", False):
        paidoff_caps = DERIVED_DATA+ '/existing_infrastructure/capacities.csv'
    rule add_existing_baseyear:
        params:
            baseyear = BASEYEAR,
            add_build_year_to_new_assets = False,
            vre_carriers = ["onwind", "offwind", "solar"],
        input:
            network=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
            tech_costs=COSTS_DATA + "/costs_{planning_horizons}.csv",
            cop_name=DERIVED_CUTOUT + "/heating/hp_cop.h5",
            installed_capacities = path_manager.infrastructure() + '/capacities.csv',
            paid_off_capacities_remind = paidoff_caps,
        output: RESULTS_DIR+ '/prenetworks-brownfield/ntwk_{planning_horizons}.nc'
        threads: 1
        resources: mem_mb=2000
        script: "scripts/add_existing_baseyear.py"

    rule solve_networks:
        params:
            solving = config["solving"],
        input:
            network_name=RESULTS_DIR+ f'/prenetworks{add_brownfield}/' +'ntwk_{planning_horizons}.nc',
        output:
            network_name=RESULTS_DIR+ '/postnetworks/ntwk_{planning_horizons}.nc'
        log:
            solver = LOG_DIR + "/solve_network_postnetworks/ntwk_{planning_horizons}.log"
        threads: 4
        resources: mem_mb=35000
        script: "scripts/solve_network.py"


elif config["foresight"] == "myopic":
    rule prepare_base_networks_2020:
        input:
            edges= "resources/data/grids/edges.txt",
            edges_existing = "resources/data/grids/edges_current.csv",
            heat_demand_profile=DERIVED_DATA + f"/heating-cutout_{CUTOUT_NAME}/"+"heat_demand_profile_{planning_horizons}.h5",
            central_fraction="resources/data/heating/DH_city_town_2020.h5",
            solar_thermal_name=DERIVED_CUTOUT+f"/heating/solar_thermal-{config['solar_thermal_angle']}.h5",
            cop_name=DERIVED_CUTOUT+"/heating/hp_cop.h5",
            elec_load=DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
            # TODO: metadata for file, why does it need to be h5?
            tech_costs= COSTS_DATA + "/costs_{planning_horizons}.csv",
            province_shape="resources/data/province_shapes/CHN_adm1.shp",
            **{f"profile_{tech}": DERIVED_CUTOUT +f"/profile_{tech}-{rsc_params[tech]}.nc" 
                for tech in config['renewable']},
        output:
            network_name=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
        wildcard_constraints:
            planning_horizons=2020 #only applies to baseyear
        threads: 1
        resources: mem_mb=10000
        script: "scripts/prepare_base_network_2020.py"

    rule prepare_base_networks:
        input:
            edges = "resources/data/grids/edges.txt",
            biomass_potential=DERIVED_COMMON+"/"+"p_nom/biomass_potential.h5",
            cop_name= DERIVED_CUTOUT+"/heating/hp_cop.h5",
            central_fraction="resources/data/heating/DH_city_town_2020.h5",
            heat_demand_profile= DERIVED_DATA + f"/heating-cutout_{CUTOUT_NAME}/"+"heat_demand_profile_{planning_horizons}.h5",
            solar_thermal_name=DERIVED_CUTOUT + f"/heating/solar_thermal-{config['solar_thermal_angle']}.h5",
            elec_load=DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
            tech_costs= COSTS_DATA + "/costs_{planning_horizons}.csv",
            province_shape="resources/data/province_shapes/CHN_adm1.shp",
            **{f"profile_{tech}": DERIVED_CUTOUT +f"/profile_{tech}-{rsc_params[tech]}.nc" 
                for tech in config['renewable']},
        output:
            network_name=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
        threads: 1
        resources: mem_mb=10000
        script: "scripts/prepare_base_network.py"

    ruleorder: prepare_base_networks_2020 > prepare_base_networks

    rule add_existing_baseyear:
        params:
            baseyear = BASEYEAR,
            add_build_year_to_new_assets = False,
        input:
            network=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
            tech_costs=COSTS_DATA + "/costs_{planning_horizons}.csv",
            cop_name=DERIVED_CUTOUT + "/heating/hp_cop.h5",
            installed_capacities = DERIVED_DATA+ '/existing_infrastructure/capacities_{planning_horizons}.csv',
        output: RESULTS_DIR+ '/prenetworks-brownfield/ntwk_{planning_horizons}.nc'
        threads: 1
        resources: mem_mb=2000
        wildcard_constraints:
            planning_horizons=config['scenario']['planning_horizons'][0] #only applies to baseyear
        threads: 1
        script: "scripts/add_existing_baseyear.py"

    def solved_previous_horizon(wildcards):
        planning_horizons = config["scenario"]["planning_horizons"]
        i = planning_horizons.index(int(wildcards.planning_horizons))
        planning_horizon_p = str(planning_horizons[i-1])
        return RESULTS_DIR+ "/postnetworks/ntwk_" + planning_horizon_p + ".nc"

    rule add_brownfield:
        input:
            network=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
            network_p=solved_previous_horizon,#solved network at previous time step
            costs="resources/data/costs/costs_{planning_horizons}.csv",
            **{f"profile_{tech}": DERIVED_CUTOUT +f"/profile_{tech}.nc"
                for tech in config['renewable']}
        output:
            network_name = RESULTS_DIR+ '/prenetworks-brownfield/ntwk_{planning_horizons}.nc',
        threads: 4
        resources: mem_mb=10000
        script: "scripts/add_brownfield.py"

    ruleorder: add_existing_baseyear > add_brownfield

    rule solve_network_myopic:
        params:
            solving = config["solving"],
        input:
            network=RESULTS_DIR+ '/prenetworks-brownfield/ntwk_{planning_horizons}.nc'
        output:
            network_name = RESULTS_DIR+ '/postnetworks/ntwk_{planning_horizons}.nc'
        log:
            solver = LOG_DIR + "/solve_network_myopic/{planning_horizons}.log"
        threads: 4
        resources: mem_mb = 80000
        script: "scripts/solve_network_myopic.py"


# run with `snakemake results/dag/rules_graph.png -f --cores 1`
rule dag:
    message:
        "Creating DAG of workflow."
    output:
        dag_dot="results/dag/dag.dot",
        dag_pdf="results/dag/dag.pdf",
        dag_png="results/dag/dag.png",
        rules_dot="results/dag/rules_graph.dot",
        rules_pdf="results/dag/rules_graph.pdf",
        rules_svg="results/dag/rules_graph.svg",
        rules_png="results/dag/rules_graph.png",
    conda:
        "envs/environment.yaml"
    shell:
        r"""
        snakemake --dag --quiet | sed -n "/digraph/,\$p" > {output.dag_dot}
        dot -Tpdf -o {output.dag_pdf} {output.dag_dot}
        dot -Tpng -o {output.dag_png} {output.dag_dot}
        snakemake --rulegraph --quiet | sed -n "/digraph/,\$p" > {output.rules_dot}
        dot -Tpdf -o {output.rules_pdf} {output.rules_dot}
        dot -Tsvg -o {output.rules_svg} {output.rules_dot}
        dot -Tpng -o {output.rules_png} {output.rules_dot}
        """

onerror:
    res_dir = expand(RESULTS_DIR, **config["scenario"])[0]
    if not os.path.exists(res_dir):
        os.makedirs(res_dir)
    try:
        yaml.dump(config, open(res_dir + "/run_config.yaml", "w"))
    except TypeError as e:
        logging.warning(f"Could not copy config file: {e}")

onsuccess:
    res_dir = expand(RESULTS_DIR, **config["scenario"])[0]
    try:
        with open(res_dir + "/run_config.yaml", "w") as f:
            yaml.dump(config, f )
    except TypeError as e:
        logging.warning(f"Could not copy config file: {e}")
