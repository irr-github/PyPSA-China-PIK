# SPDX-FileCopyrightText: : 2025 The PyPSA-China Authors
# SPDX-License-Identifier: MIT

import yaml
import shutil
from pathlib import Path
from snakemake.utils import min_version
import logging
import os.path

from os.path import abspath, getctime
from scripts._helpers import PathManager, get_cutout_params, ConfigManager

# NB: duplicated parameters will be overwritten by the last read cfg
configfile: "config/default_config.yaml"
configfile: "config/technology_config.yaml"
configfile: "config/plot_config.yaml"

# ====== make paths =======
config_manager = ConfigManager(config)
config = config_manager.handle_scenarios()

path_manager = PathManager(config)
RESULTS_DIR = path_manager.results_dir()
DERIVED_DATA = path_manager.derived_data_dir(shared=False)
DERIVED_COMMON = path_manager.derived_data_dir(shared=True)
LOG_DIR = path_manager.logs_dir()
LOGS_COMMON = "logs"
LU_RASTER = path_manager.landuse_raster_data()
CUTOUTS_DIR = path_manager.cutouts_dir()

# ====== include rules ======= (after paths are set!)
include: "rules/postprocess.smk"
include: "rules/fetch_data.smk"

localrules: plot_all, build_population, dag, fetch_region_shapes

# ====== set global parameters =======
ATLITE_NPROCESSES = config['atlite'].get('nprocesses', 4)
CUTOUT_NAME= config["atlite"]["cutout_name"]
CUTOUT_PATH = os.path.join(CUTOUTS_DIR,CUTOUT_NAME + ".nc")
# ====== set up snakemake providers =======
storage:
    provider="http",

# ======= PSEUDO RULES TO EXECUTE WORKFLOW =========
if config["run"].get("is_test", False):
    rule test_workflow:
        input:
            expand(RESULTS_DIR+ '/postnetworks/ntwk_{planning_horizons}.nc',   
            **{k: v for k, v in config["scenario"].items() if k != "planing_horizons"},
            ),

elif config["foresight"] in ["overnight", "myopic"]:
    rule plot_all:
        input:
            expand(
                RESULTS_DIR+ '/plots/summary/pathway_costs.png',
                **{k: v for k, v in config["scenario"].items() if k != "planning_horizons"},
            ),
            # network plot
            expand(
                RESULTS_DIR+"/plots/networks/ntwk_{planning_horizons}-cost.png",      
                **config["scenario"]
            ),
            expand(RESULTS_DIR+"/plots/statistics_{planning_horizons}/", **config["scenario"]),
            expand(RESULTS_DIR + "/plots/snapshots_{planning_horizons}/", **config["scenario"]),

else:
    raise ValueError("Invalid scenario config: {}".format(config["foresight"]))

rule process_config:
    output:
        config="config_test.yaml"
    script:
        "scripts/process_config.py"
#    ======== Workflow ===========
rule build_population:
    input:
        # https://www.stats.gov.cn/sj/ndsj/2023/indexeh.htm
        population="resources/data/population/population_from_national_data.csv"
    output:
        population=DERIVED_COMMON+"/"+"population/population.h5"
    threads: 1
    resources: mem_mb=1000
    script: "scripts/build_population.py"

if config['enable'].get('build_cutout', False):
    rule build_cutout:
        input:
            regions_onshore="resources/data/regions/regions_onshore.geojson",
            regions_offshore="resources/data/regions/regions_offshore.geojson"
        output: CUTOUT_PATH,
        log: LOGS_COMMON + f"/build_cutout/{CUTOUT_NAME}.log"
        benchmark: f"benchmarks/build_cutout_{CUTOUT_NAME}"
        threads: ATLITE_NPROCESSES
        resources: mem_mb=ATLITE_NPROCESSES * 1000
        script: "scripts/build_cutout.py"

rule build_population_gridcell_map:
    input:
        cutout=CUTOUT_PATH,
        province_populations=DERIVED_COMMON+"/population/population.h5",
        population_density_grid="resources/data/population/pop_density_china.nc",
        # TODO directly link to output of fetch region shapes
        # admin 1 level = first administrative level within country
        province_shape=DERIVED_COMMON+"/province_shapes/CHN_adm1.shp",
    output:
        population_map=DERIVED_COMMON+"/"+"population/population_gridcell_map.h5"
    log: LOGS_COMMON+"/build_population_gridcell_map.log"
    threads: 1
    resources: mem_mb=35000
    script: "scripts/build_population_gridcell_map.py"

rule build_solar_thermal_profiles:
    input:
        cutout=CUTOUT_PATH,
        population_map=DERIVED_COMMON+"/"+"population/population_gridcell_map.h5"
    output:
        profile_solar_thermal = DERIVED_COMMON+f"/cutout_{CUTOUT_NAME}/heating/solar_thermal-{config['solar_thermal_angle']}.h5"
    log: LOGS_COMMON + "/build_solar_thermal_profiles.log"
    threads: 8
    resources: mem_mb=30000
    script: "scripts/build_solar_thermal_profiles.py"

rule build_temperature_profiles:
    input:
        population_map=DERIVED_COMMON+"/"+"population/population_gridcell_map.h5",
        cutout=CUTOUT_PATH
    output:
        temp=DERIVED_COMMON+f"/cutout_{CUTOUT_NAME}/heating/temperature.h5"
    log: LOGS_COMMON + "/build_temperature_profiles.log"
    threads: 8
    resources: mem_mb=30000
    script: "scripts/build_temperature_profiles.py"

rule build_cop_profiles:
    input:
        population_map=DERIVED_COMMON+"/"+"population/population_gridcell_map.h5",
        cutout=CUTOUT_PATH,
        temp=DERIVED_COMMON+f"/cutout_{CUTOUT_NAME}/heating/temperature.h5"
    output:
        cop=DERIVED_COMMON+f"/cutout_{CUTOUT_NAME}/heating/hp_cop.h5"
    threads: 8
    resources: mem_mb=30000
    script: "scripts/build_cop_profiles.py"

rule build_renewable_potential:
    input:
        Build_up_raster=f"{LU_RASTER}/Build_up.tif",
        Grass_raster=f"{LU_RASTER}/Grass.tif",
        Bare_raster=f"{LU_RASTER}/Bare.tif",
        Shrubland_raster=f"{LU_RASTER}/Shrubland.tif",
        # GEBCO bathymetry (water depth)
        gebco=f"{LU_RASTER}/GEBCO_tiff/gebco_2024_CN.tif",
        # natural reserves data
        natura1='resources/data/landuse_availability/WDPA_WDOECM_Oct2024_Public_CN_shp_0/WDPA_WDOECM_Oct2024_Public_CN_shp-polygons.shp',
        natura2='resources/data/landuse_availability/WDPA_WDOECM_Oct2024_Public_CN_shp_1/WDPA_WDOECM_Oct2024_Public_CN_shp-polygons.shp',
        natura3='resources/data/landuse_availability/WDPA_WDOECM_Oct2024_Public_CN_shp_2/WDPA_WDOECM_Oct2024_Public_CN_shp-polygons.shp',
        provinces_shp=DERIVED_COMMON+"/province_shapes/CHN_adm1.shp",
        offshore_province_shapes=DERIVED_COMMON + "/regions/provinces_offshore.geojson",
        cutout= CUTOUT_PATH,
    output:
        **{f"{tech}_profile": DERIVED_COMMON +f"/cutout_{CUTOUT_NAME}/profile_{tech}.nc"
            for tech in config['Technique']}
    log: LOGS_COMMON + f"/build_renewable_potential_{CUTOUT_NAME}.log"
    threads: ATLITE_NPROCESSES
    resources: mem_mb=ATLITE_NPROCESSES * 5000
    script: "scripts/build_renewable_potential.py"

# TODO check whether energy totals still needed
rule build_load_profiles:
    input:
        population = DERIVED_COMMON+"/"+"population/population.h5",
        population_map = DERIVED_COMMON+"/"+"population/population_gridcell_map.h5",
        cutout = CUTOUT_PATH,
        intraday_profiles="resources/data/heating/heat_load_profile_DK_AdamJensen.csv",
        space_heat_demand="resources/data/heating/SPH_2020.csv",
        elec_load_projs = "resources/data/load/Province_Load_2020_2060.csv",
        province_codes = "resources/data/regions/province_codes.csv",
        hrly_regional_ac_load = "resources/data/load/Hourly_demand_of_31_province_China_modified_V2.1.csv",
    output:
        # TODO consider splitting into two rules so elect+hrly can be used DERIVED COMMON
        elec_load_hrly = DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
        heat_demand_profile = DERIVED_DATA + f"/heating-cutout_{CUTOUT_NAME}/"+"heat_demand_profile_{planning_horizons}.h5",
        energy_totals_name = DERIVED_DATA + "/" +f"energy_totals_{CUTOUT_NAME}_"+"{planning_horizons}.h5"
    log: LOG_DIR + "/build_load_profiles/build_{planning_horizons}"+f"_{CUTOUT_NAME}.log"
    threads: ATLITE_NPROCESSES
    resources: mem_mb = ATLITE_NPROCESSES * 5000
    script: "scripts/build_load_profiles.py"

rule build_biomass_potential:
    input:
        # from doi.org/10.1038/s41467-021-23282-x
        biomass_feedstocks = "resources/data/p_nom/41467_2021_23282_MOESM4_ESM.xlsx"
    log:
        LOG_DIR + "/build_biomass_potential.log"
    output:
        biomass_potential = DERIVED_DATA+"/"+"p_nom/biomass_potential.h5"
    threads: ATLITE_NPROCESSES
    resources: mem_mb = ATLITE_NPROCESSES * 5000
    script: "scripts/build_biomass_potential.py"


if config["foresight"] in ["overnight"]:
    rule prepare_networks:
        input:
            heat_demand_profile=DERIVED_DATA + f"/heating-cutout_{CUTOUT_NAME}/"+"heat_demand_profile_{planning_horizons}.h5",
            central_fraction="resources/data/heating/DH_city_town_2020.h5",
            solar_thermal_name=DERIVED_COMMON+f"/cutout_{CUTOUT_NAME}/heating/solar_thermal-{config['solar_thermal_angle']}.h5",
            cop_name=DERIVED_COMMON+f"/cutout_{CUTOUT_NAME}/heating/hp_cop.h5",
            elec_load=DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
            intraday_profiles="resources/data/heating/heat_load_profile_DK_AdamJensen.csv",
            tech_costs = "resources/data/costs/costs_{planning_horizons}.csv",
            province_shape=DERIVED_COMMON+"/province_shapes/CHN_adm1.shp",
            **{f"profile_{tech}": DERIVED_COMMON +f"/cutout_{CUTOUT_NAME}/profile_{tech}.nc" for tech in config['renewable']}
        output:
            network_name=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
        threads: 1
        resources: mem_mb=10000
        script: "scripts/prepare_network.py"

    rule solve_networks:
        params:
            solving = config["solving"],
        input:
            network_name=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
        output:
            network_name=RESULTS_DIR+ '/postnetworks/ntwk_{planning_horizons}.nc'
        log:
            solver = LOG_DIR + "/solve_network_postnetworks/ntwk_{planning_horizons}.log"
        threads: 4
        resources: mem_mb=35000
        script: "scripts/solve_network.py"

elif config["foresight"] == "myopic":
    rule prepare_base_networks_2020:
        input:
            edges= "resources/data/grids/edges.txt",
            edges_existing = "resources/data/grids/edges_current.csv",
            heat_demand_profile=DERIVED_DATA + f"/heating-cutout_{CUTOUT_NAME}/"+"heat_demand_profile_{planning_horizons}.h5",
            central_fraction="resources/data/heating/DH_city_town_2020.h5",
            solar_thermal_name=DERIVED_COMMON+f"/cutout_{CUTOUT_NAME}/heating/solar_thermal-{config['solar_thermal_angle']}.h5",
            cop_name=DERIVED_COMMON+f"/cutout_{CUTOUT_NAME}/heating/hp_cop.h5",
            elec_load=DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
            # TODO: metadata for file, why does it need to be h5?
            tech_costs= "resources/data/costs/costs_{planning_horizons}.csv",
            province_shape=DERIVED_COMMON +"/province_shapes/CHN_adm1.shp",
            **{f"profile_{tech}": DERIVED_COMMON +f"/cutout_{CUTOUT_NAME}/profile_{tech}.nc"
               for tech in config['renewable']}
        output:
            network_name=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
        wildcard_constraints:
            planning_horizons=2020 #only applies to baseyear
        threads: 1
        resources: mem_mb=10000
        script: "scripts/prepare_base_network_2020.py"

    rule prepare_base_networks:
        input:
            edges = "resources/data/grids/edges.txt",
            biomass_potental = DERIVED_DATA+"/"+"p_nom/biomass_potential.h5",
            cop_name=DERIVED_COMMON+f"/cutout_{CUTOUT_NAME}/heating/hp_cop.h5",
            central_fraction="resources/data/heating/DH_city_town_2020.h5",
            heat_demand_profile= DERIVED_DATA + f"/heating-cutout_{CUTOUT_NAME}/"+"heat_demand_profile_{planning_horizons}.h5",
            solar_thermal_name=DERIVED_COMMON+f"/cutout_{CUTOUT_NAME}/heating/solar_thermal-{config['solar_thermal_angle']}.h5",
            elec_load=DERIVED_DATA + "/load/regio_hrly_ac_load_{planning_horizons}.h5",
            tech_costs= "resources/data/costs/costs_{planning_horizons}.csv",
            province_shape=DERIVED_COMMON+"/province_shapes/CHN_adm1.shp",
            **{f"profile_{tech}": DERIVED_COMMON +f"/cutout_{CUTOUT_NAME}/profile_{tech}.nc"
               for tech in config['renewable']}
        output:
            network_name=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
        threads: 1
        resources: mem_mb=10000
        script: "scripts/prepare_base_network.py"

    ruleorder: prepare_base_networks_2020 > prepare_base_networks

    rule add_existing_baseyear:
        input:
            network=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
            tech_costs="resources/data/costs/costs_{planning_horizons}.csv",
            cop_name=DERIVED_COMMON+f"/cutout_{CUTOUT_NAME}/heating/hp_cop.h5",
            **{f"existing_{tech}": f"resources/data/existing_infrastructure/{tech} capacity.csv"
               for tech in config['existing_infrastructure']},
        output: RESULTS_DIR+ '/prenetworks-brownfield/ntwk_{planning_horizons}.nc'
        wildcard_constraints:
            planning_horizons=config['scenario']['planning_horizons'][0] #only applies to baseyear
        threads: 1
        resources: mem_mb=2000
        script: "scripts/add_existing_baseyear.py"

    def solved_previous_horizon(wildcards):
        planning_horizons = config["scenario"]["planning_horizons"]
        i = planning_horizons.index(int(wildcards.planning_horizons))
        planning_horizon_p = str(planning_horizons[i-1])
        return RESULTS_DIR+ "/postnetworks/ntwk_" + planning_horizon_p + ".nc"

    rule add_brownfield:
        input:
            network=RESULTS_DIR+ '/prenetworks/ntwk_{planning_horizons}.nc',
            network_p=solved_previous_horizon,#solved network at previous time step
            costs="resources/data/costs/costs_{planning_horizons}.csv",
            **{f"profile_{tech}": DERIVED_COMMON +f"/cutout_{CUTOUT_NAME}/profile_{tech}.nc"
                for tech in config['renewable']}
        output:
            network_name = RESULTS_DIR+ '/prenetworks-brownfield/ntwk_{planning_horizons}.nc',
        threads: 4
        resources: mem_mb=10000
        script: "scripts/add_brownfield.py"

    ruleorder: add_existing_baseyear > add_brownfield

    rule solve_network_myopic:
        params:
            solving = config["solving"],
        input:
            network=RESULTS_DIR+ '/prenetworks-brownfield/ntwk_{planning_horizons}.nc',
            costs="resources/data/costs/costs_{planning_horizons}.csv",
            biomass_potental= DERIVED_DATA+"/"+"p_nom/biomass_potential.h5",
        output:
            network_name = RESULTS_DIR+ '/postnetworks/ntwk_{planning_horizons}.nc'
        log:
            solver = LOG_DIR + "/solve_network_myopic/{planning_horizons}.log"
        threads: 4
        resources: mem_mb = 80000
        script: "scripts/solve_network_myopic.py"


# runme with `snakemake -t results/dag/rules_graph.png `
rule dag:
    message:
        "Creating DAG of workflow."
    output:
        # dag_dot="results/dag/dag.dot",
        # dag_pdf="results/dag/dag.pdf",
        # dag_png="results/dag/dag.png",
        rules_dot="results/dag/rules_graph.dot",
        rules_pdf="results/dag/rules_graph.pdf",
        rules_png="results/dag/rules_graph.png",
    conda:
        "envs/environment.yaml"
    shell:
        r"""&& 
        snakemake --dag | sed -n "/digraph/,\\$p" > {output.dag_dot}&&
        dot -Tpdf -o {output.dag_pdf} {output.dag_dot}&&
        dot -Tpng -o {output.dag_png} {output.dag_dot}&&
        snakemake --rulegraph plot_all | sed -n "/digraph/,\\$p" > {output.rules_dot}&&
        dot -Tpdf -o {output.rules_pdf} {output.rules_dot}&&
        dot -Tpng -o {output.rules_png} {output.rules_dot}&&
        """

onerror:
    log_out = expand(LOG_DIR + "/_latest_snakemake.log", **config["scenario"])[0]
    res_dir = expand(RESULTS_DIR, **config["scenario"])[0]
    if not os.path.exists(res_dir):
        os.makedirs(res_dir)
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)
    # log path is available from snakemake as "log"
    shutil.copy(log, os.path.dirname(log_out))
    yaml.dump(config, open(res_dir + "/run_config.yaml", "w"))

onsuccess:
    log_out = expand(LOG_DIR + "/_latest_snakemake.log", **config["scenario"])[0]
    res_dir = expand(RESULTS_DIR, **config["scenario"])[0]
    try:
        # log path is available as "log"
        shutil.copy(log, log_out)
        yaml.dump(config, open(res_dir + "/run_config.yaml", "w"))
    except FileNotFoundError as e:
        logging.warning(f"Could not copy log file: {e}")

